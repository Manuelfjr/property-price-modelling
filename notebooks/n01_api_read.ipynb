{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0f4a374",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52426a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests as r\n",
    "import re\n",
    "import zipfile\n",
    "import geopandas as gpd\n",
    "\n",
    "# model\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import (\n",
    "    r2_score,\n",
    "    mean_absolute_percentage_error,\n",
    "    mean_squared_error,\n",
    "    median_absolute_error,\n",
    "    mean_absolute_error,\n",
    "    median_absolute_error\n",
    ")\n",
    "\n",
    "# viz\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# utils\n",
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from geopy.geocoders import Nominatim\n",
    "import geopandas as gpd\n",
    "import pgeocode\n",
    "import urllib\n",
    "from shapely.geometry import Point\n",
    "from itertools import chain\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import kedro\n",
    "\n",
    "import sys\n",
    "from kedro.config import ConfigLoader\n",
    "from pathlib import Path\n",
    "PROJECT_DIR = Path.cwd().parent\n",
    "sys.path.append(str(PROJECT_DIR))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389625ff",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79b51112",
   "metadata": {},
   "outputs": [],
   "source": [
    "uf = 'PB'\n",
    "root = os.path.join(\n",
    "    '..', 'oos', # data or oos\n",
    ")\n",
    "path_raw = os.path.join(\n",
    "    root, '01_raw'\n",
    ")\n",
    "path_intermediate = os.path.join(\n",
    "    root, '02_intermediate'\n",
    ")\n",
    "path_primary = os.path.join(\n",
    "    root, '03_primary'\n",
    ")\n",
    "root_brasilapi = 'https://brasilapi.com.br/api'\n",
    "root_zap = 'https://www.zapimoveis.com.br/'\n",
    "url_path_ibge = os.path.join(\n",
    "    root, 'ibge', 'uf', 'v1'\n",
    ")\n",
    "url_path_pix = os.path.join(\n",
    "    root, 'pix', 'v1', 'participants'\n",
    ")\n",
    "url_path_zapimoveis = os.path.join(\n",
    "    root_zap, 'venda/imoveis/pb+joao-pessoa/?pagina={}'\n",
    ")\n",
    "url_path_ibge = os.path.join(\n",
    "    root, 'ibge', 'municipios', 'v1', f'{uf}?providers=dados-abertos-br,gov,wikipedia'\n",
    ")\n",
    "path_census_data = os.path.join(\n",
    "    path_raw, 'PB_20171016'\n",
    ")\n",
    "path_census_data_csv = os.path.join(\n",
    "    path_census_data,\n",
    "    f'{uf}',\n",
    "    f'Base informaçoes setores2010 universo {uf}',\n",
    "    'CSV'\n",
    ")\n",
    "\n",
    "file_path_data_merged = os.path.join(\n",
    "    path_intermediate, 'scrapping_data_concat.csv'\n",
    ")\n",
    "file_path_data_shp = os.path.join(\n",
    "    path_raw, \n",
    "    'PB_Setores_2021',\n",
    "    'PB_Setores_2021.shp'\n",
    ")\n",
    "file_path_processed = os.path.join(\n",
    "    path_primary, \"data_processed.csv\"\n",
    ")\n",
    "file_path_data_input = os.path.join(\n",
    "    path_primary, \"data_input.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2500427a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cep': '58070403',\n",
       " 'state': 'PB',\n",
       " 'city': 'João Pessoa',\n",
       " 'neighborhood': 'Cristo Redentor',\n",
       " 'street': 'Rua José Borges Coutinho',\n",
       " 'service': 'correios'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = r.get('https://brasilapi.com.br/api/cep/v1/58070403')\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96df832",
   "metadata": {},
   "source": [
    "# Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e296d18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzip_file(zip_path: str,\n",
    "               extract_path: str) -> bool:\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_path)\n",
    "    return True\n",
    "\n",
    "def replace_names(value: str) -> str:\n",
    "    value = value.replace('parking ','')\n",
    "    value = value.replace('bedroom ','')\n",
    "    value = value.replace('bathroom ','')\n",
    "    value = value.replace('area ','')\n",
    "    value = value.replace('m²','')\n",
    "    value = value.replace(' ','')\n",
    "    return value\n",
    "\n",
    "def transform_float(value: str) -> float:\n",
    "    value = value.replace(\"R$ \",\"\")\n",
    "    value = value.replace(\".\",\"\")\n",
    "    try:\n",
    "        value = float(value)\n",
    "    except:\n",
    "        value = value\n",
    "    return value\n",
    "\n",
    "def convert_to_float(x: str) -> float:\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        return -1\n",
    "\n",
    "def get_cbg(lat, long):\n",
    "    url_r = f'https://geo.fcc.gov/api/census/block/find?latitude={lat}&longitude={long}&censusYear=2020&showall=true&format=json'\n",
    "    result = requests.get(url_r)\n",
    "    return result#.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daca717d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_regex_cep(text: str) -> str:\n",
    "    padrao = r\"\\d{5}-\\d{3}\"\n",
    "    resultado = re.search(padrao,\n",
    "                          text)\n",
    "    if resultado:\n",
    "        return resultado.group()\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def search_cep(endereco):\n",
    "    geolocator = Nominatim(\n",
    "        user_agent = \"my_geocoder\"\n",
    "    )\n",
    "    location = geolocator.geocode(\n",
    "        endereco,\n",
    "        exactly_one = False\n",
    "    )\n",
    "    if location is not None:\n",
    "        cep = find_regex_cep(location[0].raw['display_name'])\n",
    "        return location, cep\n",
    "    else:\n",
    "        return location, None   \n",
    "    \n",
    "def find_census_area_by_zip(zip_code: str) -> str:\n",
    "    url = f'https://viacep.com.br/ws/{zip_code}/json/'\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        census_area = data.get('ibge')\n",
    "        return str(census_area)\n",
    "    else: \n",
    "        return -1\n",
    "#search_cep(\"Rua jose borges coutinho, 68, cristo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d12ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_connection(url: str,\n",
    "                   root_xpath: str) -> tuple:\n",
    "    # Configurar o Selenium para executar o Chrome em modo headless\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument('--headless')  # Executar o Chrome em modo headless\n",
    "    chrome_options.add_argument('--no-sandbox')\n",
    "    chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    driver.get(url)\n",
    "    limit_find, k = False, 0\n",
    "    list_local = driver.find_elements(By.XPATH, root_xpath)\n",
    "    print('- number of locals found: [{}]'.format(len(list_local)))\n",
    "    print()\n",
    "    while len(list_local)==0:\n",
    "        print(f'trying: [{k + 1}]')\n",
    "        driver.get(url_path_zapimoveis)\n",
    "        list_local = driver.find_elements(By.XPATH, root_xpath)\n",
    "        if k >= 5:\n",
    "            limit_find = True\n",
    "            break\n",
    "        k += 1\n",
    "    return driver, list_local, limit_find"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7452cfbc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def scrapping_zipimoveis(url: str) -> dict:\n",
    "    root_xpath = \"//div[@class='card-container js-listing-card']\"\n",
    "    i_xpath_price = root_xpath + \"//div[@class='simple-card__listing-prices simple-card__prices']\"\n",
    "    i_xpath_amenities = root_xpath + \"//ul[@class='feature__container simple-card__amenities']\"\n",
    "    i_xpath_feature = \".//li[contains(@class, 'feature__item')]\"\n",
    "    i_xpath_local = \".//h2[@class='simple-card__address color-dark text-regular']\"\n",
    "    try:\n",
    "\n",
    "        driver, list_local, _ = get_connection(\n",
    "            url, root_xpath\n",
    "        )\n",
    "\n",
    "        content_data = {}\n",
    "        for idx, i in enumerate(list_local):\n",
    "            ID = f'id-{i.get_attribute(\"data-id\")}'\n",
    "            #print('-- getting: [{}]'.format(ID))\n",
    "            content_data[ID] = {}\n",
    "            price = i.find_elements(By.XPATH,\n",
    "                                    i_xpath_price)\n",
    "            price_extracted = price[idx].find_element(By.TAG_NAME, \"strong\").text\n",
    "            #print('---- price: [{}]'.format(price_extracted))\n",
    "            content_data[ID]['price'] = [\n",
    "                price_extracted\n",
    "            ]\n",
    "\n",
    "            local = i.find_element(By.XPATH,\n",
    "                                   i_xpath_local)\n",
    "\n",
    "            local_extracted = local.text\n",
    "            content_data[ID]['local'] = [local_extracted]\n",
    "            #print('---- local: [{}]'.format(local_extracted))\n",
    "\n",
    "            card_amenities = i.find_elements(By.XPATH, \n",
    "                                             i_xpath_amenities)\n",
    "\n",
    "            elementos = card_amenities[idx].find_elements(By.XPATH,\n",
    "                                                          i_xpath_feature)\n",
    "            content_data[ID]['features'] = {\n",
    "                        i.get_attribute(\"class\").split(\" \")[-1][3:]: i.text.strip() for i in elementos\n",
    "                    }\n",
    "            #print()\n",
    "    except Exception as e:\n",
    "        print('Erro durante a execução:', e)\n",
    "\n",
    "    finally:\n",
    "        driver.quit()\n",
    "    return content_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e9308b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reader(url: str) -> pd.DataFrame:\n",
    "    try:\n",
    "        data = pd.read_csv(url,\n",
    "                           delimiter = ';')\n",
    "    except:\n",
    "        data = pd.read_csv(url,\n",
    "                           sep=';', \n",
    "                           encoding='latin-1')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f2cba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_coefs(x: float) -> float:\n",
    "    return np.abs(x)/(sum(np.abs(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3d0ead",
   "metadata": {},
   "source": [
    "# Read datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0beda3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzip\n",
    "if not os.path.exists(path_census_data):\n",
    "    unzip_file(\n",
    "        path_census_data+'.zip',\n",
    "        path_census_data\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d119de0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_census = {\n",
    "    i: reader(url) for i, url in file_path_census_data.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08f4261",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_shp = gpd.read_file(file_path_data_shp)\n",
    "data_shp.columns = data_shp.columns.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6d8982",
   "metadata": {},
   "source": [
    "# Concatenate census data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58121873",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, (name, content) in enumerate(data_census.items()):\n",
    "    if idx == 0:\n",
    "        data_census_merged = content.copy()\n",
    "        data_census_merged.columns = data_census_merged.columns.str.lower()\n",
    "        data_census_merged.columns = [\"cod_setor\"]+[\n",
    "            '{}_{}'.format(i, name) for i in data_census_merged.columns[1:]\n",
    "        ]\n",
    "    else:\n",
    "        content.columns = content.columns.str.lower()\n",
    "        content.columns = [\"cod_setor\"]+[\n",
    "            '{}_{}'.format(i, name) for i in content.columns[1:]\n",
    "        ]\n",
    "        data_census_merged = data_census_merged.merge(\n",
    "            content,\n",
    "            on = [\"cod_setor\"],\n",
    "            suffixes = (\n",
    "                \"_{}\".format(name).lower(),\n",
    "                \"_{}\".format(name).lower()\n",
    "            )\n",
    "        )\n",
    "        data_census_merged.columns = data_census_merged.columns.str.lower()\n",
    "    if 'v999' in data_census_merged.columns:\n",
    "        print(data_census_merged.columns)\n",
    "data_census_merged.columns = data_census_merged.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a05d05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_census_merged.drop(\n",
    "    data_census_merged.columns[data_census_merged.columns.str.contains('unnamed')],\n",
    "    axis = 1, inplace = True\n",
    ")\n",
    "data_census_merged = data_census_merged.loc[:, ~data_census_merged.columns.duplicated()]\n",
    "data_census_merged.rename(\n",
    "        columns = {\n",
    "            \"cod_setor\": \"cd_setor\"\n",
    "        }, inplace = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4f9b40",
   "metadata": {},
   "source": [
    "# Filter data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54ebed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter_joao_pessoa\n",
    "data_census_merged = data_census_merged[\n",
    "    data_census_merged.cd_setor.astype(\n",
    "        str\n",
    "    ).str.contains(\n",
    "        '2507507'\n",
    "    )\n",
    "].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47404cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter_joao_pessoa\n",
    "data_shp = data_shp[\n",
    "    data_shp.cd_setor.astype(\n",
    "        str\n",
    "    ).str.contains(\n",
    "        '2507507'\n",
    "    )\n",
    "].copy()\n",
    "data_shp.rename(\n",
    "    columns = {\n",
    "        \"cod_setor\": \"cd_setor\"\n",
    "    }, inplace = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039c6be8",
   "metadata": {},
   "source": [
    "# Scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebe8355",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pages_init = 51\n",
    "n_pages_final = 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0ac527",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_results_scrapping = {}\n",
    "for i in tqdm(range(n_pages_init, n_pages_final + 1)):\n",
    "    data_results_scrapping[\n",
    "        f'page_n{i}'\n",
    "    ] = scrapping_zipimoveis(url_path_zapimoveis.format(i))\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0893930c",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_final = {}\n",
    "errors = []\n",
    "for page, content in tqdm(data_results_scrapping.items()):\n",
    "    data_tmp = {}\n",
    "    for idx, i in enumerate(list(content.items())):\n",
    "        data_tmp[f'n{idx}'] = {}\n",
    "        data_tmp[f'n{idx}']['ID'] = i[0].replace('id-','')\n",
    "        data_tmp[f'n{idx}']['price'] = transform_float(i[1]['price'][0])\n",
    "        data_tmp[f'n{idx}']['local'] = i[1]['local']\n",
    "        for f_name, f_value in i[1]['features'].items():\n",
    "            data_tmp[f'n{idx}'][f_name] = replace_names(f_value)\n",
    "        data_tmp[f'n{idx}'] = pd.DataFrame(data_tmp[f'n{idx}'])\n",
    "    try:\n",
    "        content_final[page] = pd.concat(list(data_tmp.values()),\n",
    "                                        ignore_index = True)\n",
    "    except Exception as e:\n",
    "        errors.append((page, e))\n",
    "content_final = pd.concat(list(content_final.values()),\n",
    "                          ignore_index = True).replace('', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7bc020",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_selected = [\n",
    "    'areas',\n",
    "    'bedrooms',\n",
    "    'parking-spaces',\n",
    "    'bathrooms'\n",
    "]\n",
    "string_rows = content_final[cols_selected].apply(lambda x: x.str.contains('-', na = False))\n",
    "\n",
    "for i in cols_selected:\n",
    "    values_changed = content_final[\n",
    "        string_rows[i]\n",
    "    ][i].apply(\n",
    "        lambda x: (int(x.split(\"-\")[0])+int(x.split(\"-\")[1]))/2\n",
    "    )\n",
    "    content_final.loc[values_changed.index, i] = values_changed.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191a5f9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ceps = []\n",
    "for i in tqdm(content_final['local']):\n",
    "    try:\n",
    "        ceps.append( search_cep(i)[1] )\n",
    "    except:\n",
    "        ceps.append( np.nan )\n",
    "content_final['cep'] = ceps\n",
    "content_final['cep'] = content_final['cep'].fillna(np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a8432f",
   "metadata": {},
   "source": [
    "## Save scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c8777b",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_final.to_csv(file_path_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a154fb63",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b5b1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = [\n",
    "    \"bathrooms\"\n",
    "]\n",
    "which_rows_to_drop = [\n",
    "    'areas', \n",
    "    'bedrooms',\n",
    "    'parking-spaces'\n",
    "]\n",
    "id_tag = [\n",
    "    \"ID\"\n",
    "]\n",
    "content_final_process = content_final.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f4661b",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_final_process.price = content_final_process.price.apply(convert_to_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffd02fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "lats = []\n",
    "longs = []\n",
    "cbg = []\n",
    "nomi = pgeocode.Nominatim('br')\n",
    "for local in  tqdm(content_final_process.local):\n",
    "    if local!=None:\n",
    "        address = local + f', {uf}, Brasil'\n",
    "        try:\n",
    "\n",
    "            geolocator = Nominatim(user_agent=\"geolocalização\")\n",
    "            location = geolocator.geocode(address)\n",
    "\n",
    "            lats.append(float(location.latitude))\n",
    "            longs.append(float(location.longitude))\n",
    "\n",
    "        except:\n",
    "            lats.append(np.nan)\n",
    "            longs.append(np.nan)\n",
    "\n",
    "    else:\n",
    "        lats.append(np.nan)\n",
    "        longs.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f5b3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_final_process['lats'] = lats\n",
    "content_final_process['longs'] = longs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fbfa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar os objetos de ponto com as latitudes e longitudes\n",
    "pontos = [Point(xy) for xy in zip(content_final_process['longs'], content_final_process['lats'])]\n",
    "\n",
    "def find_cbg(shp, points):\n",
    "    cbgs = []\n",
    "    for i in tqdm(pontos):\n",
    "        cbgs.append(\n",
    "            list(data_shp.loc[data_shp.geometry.contains(i), \"cd_setor\"].values)\n",
    "        )\n",
    "    cbgs = [i[0] if i != [] else np.nan for i in cbgs]\n",
    "    #cbgs = list(chain.from_iterable(cbgs))\n",
    "    return cbgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c76fb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cbgs = find_cbg(data_shp, pontos)\n",
    "content_final_process['cd_setor'] = cbgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2908b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# order columns\n",
    "id_columns = [\n",
    "    \"ID\",\n",
    "    \"cd_setor\"\n",
    "]\n",
    "content_final_process = content_final_process[id_columns+[i for i in content_final_process.columns if i not in id_columns]]\n",
    "content_processed = content_final_process.dropna(subset = [\"cd_setor\"]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ae84dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_processed.cd_setor = content_processed.cd_setor.astype(str)\n",
    "data_census_merged.cd_setor = data_census_merged.cd_setor.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc01ca74",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged = content_processed.merge(\n",
    "    data_census_merged, \n",
    "    on = [\"cd_setor\"],\n",
    "    how = \"left\"\n",
    ")\n",
    "data_merged = data_merged.merge(\n",
    "    data_shp[[\"cd_setor\",\"nm_sit\"]],\n",
    "    on = [\"cd_setor\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "data_merged.insert(\n",
    "    4,\n",
    "    \"bairro\",\n",
    "    data_merged.local.apply(\n",
    "        lambda x: x.split(\", \")[-1]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff12617",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged.columns = data_merged.columns.str.replace(\" \",\"_\")\n",
    "columns_na = data_merged.isna().sum()[data_merged.isna().sum()!=0].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4535c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_bairros = {}\n",
    "errors = []\n",
    "for bairro in tqdm(data_merged.bairro.unique()):\n",
    "    data_bairros[bairro] = data_merged[\n",
    "        data_merged.bairro.str.contains(bairro)\n",
    "    ].reset_index(drop = True)\n",
    "    for na_col in tqdm(columns_na):\n",
    "        #print(na_col)\n",
    "        try:\n",
    "            data_bairros[bairro][na_col] = data_bairros[\n",
    "                bairro\n",
    "            ][\n",
    "                na_col\n",
    "            ].astype(\n",
    "                float\n",
    "            )\n",
    "            average = data_bairros[bairro][na_col].mean()\n",
    "            data_bairros[bairro][na_col] = data_bairros[\n",
    "                bairro\n",
    "            ][\n",
    "                na_col\n",
    "            ].fillna(\n",
    "                average\n",
    "            )\n",
    "        except Exception as e:\n",
    "            errors.append(e)\n",
    "            continue\n",
    "data_merged_not_nan = pd.concat(list(data_bairros.values()), ignore_index = True)\n",
    "data_merged_not_nan = data_merged_not_nan.dropna().reset_index(drop = True)\n",
    "data_merged_not_nan = data_merged_not_nan[\n",
    "    ~data_merged_not_nan['ID'].duplicated()\n",
    "].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0880eefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged_not_nan.drop(\n",
    "    data_merged_not_nan.columns[data_merged_not_nan.columns.str.contains(\"situacao\")],\n",
    "    axis = 1,\n",
    "    inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedce512",
   "metadata": {},
   "source": [
    "## Save data processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ed5ecc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_merged_not_nan.to_csv(file_path_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26998107",
   "metadata": {},
   "source": [
    "# Drop columns with problemns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d169f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cods_cols = list(data_merged_not_nan.columns[data_merged_not_nan.columns.str.contains(\"cod\")])\n",
    "other_cols = [\n",
    "    \"cep\",\n",
    "    \"lats\",\n",
    "    \"longs\",\n",
    "    \"local\",\n",
    "    \"nm_sit\"\n",
    "]\n",
    "all_columns = cods_cols + other_cols\n",
    "data_merged_not_nan.drop(all_columns,\n",
    "                         axis = 1, \n",
    "                         inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37d47ee",
   "metadata": {},
   "source": [
    "# Categorical columns process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0eb604",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [\n",
    "    \"bairro\"\n",
    "]\n",
    "cat_dict = {\n",
    "    \n",
    "}\n",
    "for col in cat_cols:\n",
    "    for idx, i in enumerate(data_merged_not_nan[col].unique()):\n",
    "        cat_dict[col] = {\n",
    "            i: int(idx)\n",
    "        }\n",
    "        data_merged_not_nan[col] = data_merged_not_nan[col].replace(cat_dict[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855c61d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final = data_merged_not_nan.copy()\n",
    "data_final = data_final.replace(\"X\", np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64cb422",
   "metadata": {},
   "source": [
    "## Process column with problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc81eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat in data_final.columns[data_final.columns.str.contains(\"nome\")]:\n",
    "    cat_values = {\n",
    "        i: idx for idx, i in enumerate(data_final[cat].unique())\n",
    "    }\n",
    "    data_final[cat] = data_final[cat].replace(cat_values)\n",
    "    \n",
    "for pro_col in data_final.columns:\n",
    "    try:\n",
    "        data_final[pro_col] = data_final[pro_col].astype(float)\n",
    "    except:\n",
    "        data_final[pro_col] = data_final[pro_col].astype(str).str.replace(\",\",\".\").astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e20fb57",
   "metadata": {},
   "source": [
    "## Drop bathrooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9273e4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_final.drop(\"bathrooms\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d254cb",
   "metadata": {},
   "source": [
    "# Save dataset final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44959e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final.to_csv(file_path_data_input)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
