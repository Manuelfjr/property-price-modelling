{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0f4a374",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52426a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "PROJECT_DIR = Path.cwd().parent\n",
    "sys.path.append(str(PROJECT_DIR))\n",
    "\n",
    "# basics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests as r\n",
    "import re\n",
    "import geopandas as gpd\n",
    "import json\n",
    "\n",
    "# viz\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# utils\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from geopy.geocoders import Nominatim\n",
    "import geopandas as gpd\n",
    "import pgeocode\n",
    "import urllib\n",
    "from shapely.geometry import Point\n",
    "from itertools import chain\n",
    "from kedro.config import ConfigLoader\n",
    "from ppm.utils.external_get_data import (\n",
    "    find_regex_cep,\n",
    "    search_cep,\n",
    "    find_census_area_by_zip,\n",
    "    get_connection,\n",
    "    scrapping_zipimoveis,\n",
    "    find_cbg\n",
    ")\n",
    "from ppm.utils.readers import (\n",
    "    reader,\n",
    "    unzip_file\n",
    ")\n",
    "from ppm.utils.feature_process import (\n",
    "    replace_names,\n",
    "    transform_float,\n",
    "    convert_to_float,\n",
    "    replace_na_with_mean,\n",
    "    replace_na_with_mode\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e624c582",
   "metadata": {},
   "outputs": [],
   "source": [
    "which_test = \"oos\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389625ff",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79b51112",
   "metadata": {},
   "outputs": [],
   "source": [
    "uf = 'PB'\n",
    "path_root_oos = os.path.join(\n",
    "    '..', 'oos', # data or oos\n",
    ")\n",
    "path_root_data = os.path.join(\n",
    "    '..', 'data', # data or oos\n",
    ")\n",
    "path_raw = os.path.join(\n",
    "    path_root_data, '01_raw'\n",
    ")\n",
    "path_intermediate = os.path.join(\n",
    "    path_root_oos, '02_intermediate'\n",
    ")\n",
    "path_intermediate_data = os.path.join(\n",
    "    path_root_data, '02_intermediate'\n",
    ")\n",
    "path_primary = os.path.join(\n",
    "    path_root_oos, '03_primary'\n",
    ")\n",
    "root_brasilapi = 'https://brasilapi.com.br/api'\n",
    "root_zap = 'https://www.zapimoveis.com.br/'\n",
    "url_path_zapimoveis = os.path.join(\n",
    "    root_zap, 'venda/imoveis/pb+joao-pessoa/?pagina={}'\n",
    ")\n",
    "path_census_data = os.path.join(\n",
    "    path_raw, 'PB_20171016'\n",
    ")\n",
    "path_census_data_csv = os.path.join(\n",
    "    path_census_data,\n",
    "    f'{uf}',\n",
    "    f'Base informaçoes setores2010 universo {uf}',\n",
    "    'CSV'\n",
    ")\n",
    "path_columns_cat = os.path.join(\n",
    "    path_intermediate, \"categorical_dict\"\n",
    ")\n",
    "path_columns_cat_data = os.path.join(\n",
    "    path_intermediate_data, \"categorical_dict\"\n",
    ")\n",
    "\n",
    "file_path_data_merged = os.path.join(\n",
    "    path_intermediate, 'scrapping_data_concat.csv'\n",
    ")\n",
    "file_path_data_shp = os.path.join(\n",
    "    path_raw, \n",
    "    'PB_Setores_2021',\n",
    "    'PB_Setores_2021.shp'\n",
    ")\n",
    "file_path_shp_processed = os.path.join(\n",
    "    path_intermediate_data, \"data_shp_processed\"\n",
    ")\n",
    "file_path_census_processed = os.path.join(\n",
    "    path_intermediate_data, \"data_census_processed.csv\"\n",
    ")\n",
    "file_path_processed = os.path.join(\n",
    "    path_primary, \"data_processed.csv\"\n",
    ")\n",
    "file_path_processed_concat = os.path.join(\n",
    "    path_primary, \"data_processed_concat.csv\"\n",
    ")\n",
    "file_path_data_input = os.path.join(\n",
    "    path_primary, \"data_input.csv\"\n",
    ")\n",
    "file_path_categorical_replaces = os.path.join(\n",
    "    path_columns_cat, \"{}.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3d0ead",
   "metadata": {},
   "source": [
    "# Read datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0beda3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzip\n",
    "if not os.path.exists(path_census_data):\n",
    "    unzip_file(\n",
    "        path_census_data+'.zip',\n",
    "        path_census_data\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b45c443",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_census_data = {\n",
    "    i.split(\".\")[0]: os.path.join(path_census_data_csv, i)for i in os.listdir(path_census_data_csv) \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9592daee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_census_merged = pd.read_csv(file_path_census_processed)\n",
    "data_shp = gpd.read_file(file_path_shp_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039c6be8",
   "metadata": {},
   "source": [
    "# Scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebe8355",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pages_init = 61\n",
    "n_pages_final = 121 # 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0ac527",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_results_scrapping = {}\n",
    "for i in tqdm(range(n_pages_init, n_pages_final + 1)):\n",
    "    print(url_path_zapimoveis.format(i))\n",
    "    data_results_scrapping[\n",
    "        f'page_n{i}'\n",
    "    ] = scrapping_zipimoveis(url_path_zapimoveis.format(i))\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0893930c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "content_final = {}\n",
    "errors = []\n",
    "for page, content in tqdm(data_results_scrapping.items()):\n",
    "    data_tmp = {}\n",
    "    for idx, i in enumerate(list(content.items())):\n",
    "        data_tmp[f'n{idx}'] = {}\n",
    "        data_tmp[f'n{idx}']['ID'] = i[0].replace('id-','')\n",
    "        data_tmp[f'n{idx}']['price'] = transform_float(i[1]['price'][0])\n",
    "        data_tmp[f'n{idx}']['local'] = i[1]['local']\n",
    "        data_tmp[f'n{idx}']['highlight'] = i[1]['highlight']\n",
    "        for f_name, f_value in i[1]['features'].items():\n",
    "            data_tmp[f'n{idx}'][f_name] = replace_names(f_value)\n",
    "        data_tmp[f'n{idx}'] = pd.DataFrame(data_tmp[f'n{idx}'])\n",
    "    try:\n",
    "        content_final[page] = pd.concat(list(data_tmp.values()),\n",
    "                                        ignore_index = True)\n",
    "    except Exception as e:\n",
    "        errors.append((page, e))\n",
    "content_final = pd.concat(list(content_final.values()),\n",
    "                          ignore_index = True).replace('', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7bc020",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_selected = [\n",
    "    'areas',\n",
    "    'bedrooms',\n",
    "    'parking-spaces',\n",
    "    'bathrooms'\n",
    "]\n",
    "string_rows = content_final[cols_selected].apply(lambda x: x.str.contains('-', na = False))\n",
    "\n",
    "for i in cols_selected:\n",
    "    values_changed = content_final[\n",
    "        string_rows[i]\n",
    "    ][i].apply(\n",
    "        lambda x: (int(x.split(\"-\")[0])+int(x.split(\"-\")[1]))/2\n",
    "    )\n",
    "    content_final.loc[values_changed.index, i] = values_changed.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191a5f9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ceps = []\n",
    "for i in tqdm(content_final['local']):\n",
    "    try:\n",
    "        ceps.append( search_cep(i)[1] )\n",
    "    except:\n",
    "        ceps.append( np.nan )\n",
    "content_final['cep'] = ceps\n",
    "content_final['cep'] = content_final['cep'].fillna(np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a154fb63",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b5b1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = [\n",
    "    \"bathrooms\"\n",
    "]\n",
    "which_rows_to_drop = [\n",
    "    'areas', \n",
    "    'bedrooms',\n",
    "    'parking-spaces',\n",
    "    'highlight'\n",
    "]\n",
    "id_tag = [\n",
    "    \"ID\"\n",
    "]\n",
    "content_final_process = content_final.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f4661b",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_final_process.price = content_final_process.price.apply(convert_to_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffd02fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "lats = []\n",
    "longs = []\n",
    "cbg = []\n",
    "nomi = pgeocode.Nominatim('br')\n",
    "for local in  tqdm(content_final_process.local):\n",
    "    if local!=None:\n",
    "        address = local + f', {uf}, Brasil'\n",
    "        try:\n",
    "                                                                                                                        \n",
    "            geolocator = Nominatim(user_agent=\"geolocalização\")\n",
    "            location = geolocator.geocode(address)\n",
    "\n",
    "            lats.append(float(location.latitude))\n",
    "            longs.append(float(location.longitude))\n",
    "\n",
    "        except:\n",
    "            lats.append(np.nan)\n",
    "            longs.append(np.nan)\n",
    "\n",
    "    else:\n",
    "        lats.append(np.nan)\n",
    "        longs.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f5b3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_final_process['lats'] = lats\n",
    "content_final_process['longs'] = longs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fbfa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar os objetos de ponto com as latitudes e longitudes\n",
    "pontos = [Point(xy) for xy in zip(content_final_process['longs'], content_final_process['lats'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c76fb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cbgs = find_cbg(data_shp, pontos)\n",
    "content_final_process['cd_setor'] = cbgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2908b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# order columns\n",
    "id_columns = [\n",
    "    \"ID\",\n",
    "    \"cd_setor\"\n",
    "]\n",
    "content_final_process = content_final_process[id_columns+[i for i in content_final_process.columns if i not in id_columns]]\n",
    "content_processed = content_final_process.dropna(subset = [\"cd_setor\"]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ae84dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_processed.cd_setor = content_processed.cd_setor.astype(str)\n",
    "data_census_merged.cd_setor = data_census_merged.cd_setor.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056403fb",
   "metadata": {},
   "source": [
    "## Save scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c612994",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_processed.to_csv(file_path_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523485cc",
   "metadata": {},
   "source": [
    "# Concat census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc01ca74",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged = content_processed.merge(\n",
    "    data_census_merged, \n",
    "    on = [\"cd_setor\"],\n",
    "    how = \"left\"\n",
    ")\n",
    "data_merged = data_merged.merge(\n",
    "    data_shp[[\"cd_setor\",\"nm_sit\"]],\n",
    "    on = [\"cd_setor\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "data_merged.insert(\n",
    "    4,\n",
    "    \"bairro\",\n",
    "    data_merged.local.apply(\n",
    "        lambda x: x.split(\", \")[-1]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff12617",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged.columns = data_merged.columns.str.replace(\" \",\"_\")\n",
    "columns_na = list(data_merged.isna().sum()[data_merged.isna().sum()!=0].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4535c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_bairros, errors = replace_na_with_mean(data_merged, columns_na, 'bairro')\n",
    "data_merged_not_nan = pd.concat(list(data_bairros.values()), ignore_index = True)\n",
    "data_merged_not_nan = data_merged_not_nan[\n",
    "    ~data_merged_not_nan['ID'].duplicated()\n",
    "].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0880eefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged_not_nan.drop(\n",
    "    data_merged_not_nan.columns[data_merged_not_nan.columns.str.contains(\"situacao\")],\n",
    "    axis = 1,\n",
    "    inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedce512",
   "metadata": {},
   "source": [
    "## Save data processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ed5ecc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_merged_not_nan.to_csv(file_path_processed_concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26998107",
   "metadata": {},
   "source": [
    "# Drop columns with problemns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f8d169f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cods_cols = list(data_merged_not_nan.columns[data_merged_not_nan.columns.str.contains(\"cod\")])\n",
    "other_cols = [\n",
    "    \"cep\",\n",
    "    \"lats\",\n",
    "    \"longs\",\n",
    "    \"local\",\n",
    "    \"nm_sit\"\n",
    "]\n",
    "all_columns = cods_cols + other_cols\n",
    "data_merged_not_nan.drop(all_columns,\n",
    "                         axis = 1, \n",
    "                         inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37d47ee",
   "metadata": {},
   "source": [
    "# Categorical columns process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "57eae587",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(path_columns_cat):\n",
    "    os.makedirs(path_columns_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d403f4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols_nome = [\n",
    "    'nome_grande_regiao_basico_pb',\n",
    "    'nome_da_uf__basico_pb',\n",
    "    'nome_da_meso_basico_pb',\n",
    "    'nome_da_micro_basico_pb',\n",
    "    'nome_da_rm_basico_pb',\n",
    "    'nome_do_municipio_basico_pb',\n",
    "    'nome_do_distrito_basico_pb',\n",
    "    'nome_do_subdistrito_basico_pb',\n",
    "]\n",
    "data_merged_not_nan.drop(cat_cols_nome, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "be0eb604",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [\n",
    "        \"bairro\"\n",
    "    ] + [\n",
    "        \"nome_do_bairro_basico_pb\",\n",
    "        \"highlight\"\n",
    "    ]\n",
    "if os.path.exists(path_columns_cat_data):\n",
    "    cat_dict_all = {}\n",
    "    for col in os.listdir(path_columns_cat_data):\n",
    "        json_cat = json.load(open(os.path.join(path_columns_cat_data, col), 'r'))\n",
    "        cat_dict_all[col.split('.')[0]] = json_cat\n",
    "else:\n",
    "    cat_dict_all = {}\n",
    "    for col in cat_cols:\n",
    "        cat_dict = {}\n",
    "        for idx, i in enumerate(data_merged_not_nan[col].unique()):\n",
    "            cat_dict[i] = idx\n",
    "        cat_dict_all[col] = cat_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "48a73b2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/53 [00:00<?, ?it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 42.64it/s]\u001b[A\n",
      "\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 13.76it/s]\u001b[A\n",
      "  4%|█▋                                          | 2/53 [00:00<00:07,  7.22it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 68.10it/s]\u001b[A\n",
      "\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 52.08it/s]\u001b[A\n",
      "  8%|███▎                                        | 4/53 [00:00<00:04, 11.41it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 98.96it/s]\u001b[A\n",
      "\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 111.30it/s]\u001b[A\n",
      "\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 60.42it/s]\u001b[A\n",
      " 13%|█████▊                                      | 7/53 [00:00<00:02, 16.01it/s]\n",
      "100%|███████████████████████████████████████████| 1/1 [00:00<00:00, 1075.74it/s]\u001b[A\n",
      "\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 73.60it/s]\u001b[A\n",
      "\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 116.33it/s]\u001b[A\n",
      "\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 973.38it/s]\u001b[A\n",
      "\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 150.67it/s]\u001b[A\n",
      " 23%|█████████▋                                 | 12/53 [00:00<00:01, 25.06it/s]\n",
      "100%|███████████████████████████████████████████| 1/1 [00:00<00:00, 1424.70it/s]\u001b[A\n",
      "\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 238.77it/s]\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████| 1/1 [00:00<00:00, 1040.77it/s]\u001b[A\n",
      "\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 112.41it/s]\u001b[A\n",
      "\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 143.98it/s]\u001b[A\n",
      " 32%|█████████████▊                             | 17/53 [00:00<00:01, 31.76it/s]\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 211.94it/s]\u001b[A\n",
      "\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 167.54it/s]\u001b[A\n",
      "\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 310.53it/s]\u001b[A\n",
      "\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 153.79it/s]\u001b[A\n",
      "\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 243.36it/s]\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████| 1/1 [00:00<00:00, 1324.80it/s]\u001b[A\n",
      " 43%|██████████████████▋                        | 23/53 [00:00<00:00, 39.42it/s]\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 238.04it/s]\u001b[A\n",
      "\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 801.36it/s]\u001b[A\n",
      "\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 104.74it/s]\u001b[A\n",
      "\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 696.61it/s]\u001b[A\n",
      "\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 175.78it/s]\u001b[A\n",
      "\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 392.32it/s]\u001b[A\n",
      " 55%|███████████████████████▌                   | 29/53 [00:00<00:00, 44.36it/s]\n",
      "100%|███████████████████████████████████████████| 1/1 [00:00<00:00, 1210.48it/s]\u001b[A\n",
      "\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 825.98it/s]\u001b[A\n",
      "\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 557.23it/s]\u001b[A\n",
      "\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 170.20it/s]\u001b[A\n",
      "\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 799.98it/s]\u001b[A\n",
      "\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 596.29it/s]\u001b[A\n",
      " 66%|████████████████████████████▍              | 35/53 [00:01<00:00, 45.95it/s]\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 783.40it/s]\u001b[A\n",
      "\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 468.38it/s]\u001b[A\n",
      "\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 694.54it/s]\u001b[A\n",
      "\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 923.86it/s]\u001b[A\n",
      "\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 870.19it/s]\u001b[A\n",
      " 75%|████████████████████████████████▍          | 40/53 [00:01<00:00, 45.37it/s]\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 149.33it/s]\u001b[A\n",
      "\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 157.82it/s]\u001b[A\n",
      "\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 213.17it/s]\u001b[A\n",
      "\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 907.07it/s]\u001b[A\n",
      "\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 867.49it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▌      | 45/53 [00:01<00:00, 43.93it/s]\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 184.51it/s]\u001b[A\n",
      "\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 912.00it/s]\u001b[A\n",
      "\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 769.31it/s]\u001b[A\n",
      "\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 420.61it/s]\u001b[A\n",
      "\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 609.28it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▌  | 50/53 [00:01<00:00, 44.45it/s]\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 757.23it/s]\u001b[A\n",
      "\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 175.82it/s]\u001b[A\n",
      "\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 892.60it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 53/53 [00:01<00:00, 36.07it/s]\n"
     ]
    }
   ],
   "source": [
    "data_merged_not_nan, e3 = replace_na_with_mode(\n",
    "    data_merged_not_nan,\n",
    "    ['highlight'],\n",
    "    'bairro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "855c61d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final = data_merged_not_nan.copy()\n",
    "data_final = data_final.replace(\"X\", np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "de4aacd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JOÃO PESSOA (demais setores)\n",
      "nan\n",
      "Mumbaba\n",
      "Costa E Silva\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "cat_tmp = {}\n",
    "for column_name, content_cat in cat_dict_all.items():\n",
    "    if len(set(data_final[column_name].unique()) - set(cat_dict_all[column_name].keys())) != 0:\n",
    "        cat_tmp[column_name] = {}\n",
    "        for i in set(data_final[column_name].unique()) - set(cat_dict_all[column_name].keys()):\n",
    "            cat_tmp[column_name][i] = -1\n",
    "        data_final[column_name].replace(\n",
    "            cat_dict_all[column_name]|cat_tmp[column_name], inplace = True\n",
    "        )\n",
    "    else:\n",
    "        data_final[column_name].replace(cat_dict_all[column_name], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ba3ddb",
   "metadata": {},
   "source": [
    "### Save categorical labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "56653b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_col_cat, i_content_cat in cat_dict_all.items():\n",
    "    with open(file_path_categorical_replaces.format(i_col_cat), 'w') as file:\n",
    "        json.dump(i_content_cat, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64cb422",
   "metadata": {},
   "source": [
    "### Process column with problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4fc81eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pro_col in data_final.columns:\n",
    "    try:\n",
    "        data_final[pro_col] = data_final[pro_col].astype(float)\n",
    "    except:\n",
    "        data_final[pro_col] = data_final[pro_col].astype(str).str.replace(\",\",\".\").astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e20fb57",
   "metadata": {},
   "source": [
    "## Drop bathrooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6e9273e4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_final.drop(\"bathrooms\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa5c804",
   "metadata": {},
   "source": [
    "## Drop last nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f13d9b3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_final = data_final.dropna().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d254cb",
   "metadata": {},
   "source": [
    "# Save dataset final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "44959e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final.to_csv(file_path_data_input)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
