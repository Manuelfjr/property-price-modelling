{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e329d0e6",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e646cb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# feature_importance\n",
    "import shap\n",
    "\n",
    "# viz\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# models\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import (\n",
    "    r2_score,\n",
    "    mean_absolute_percentage_error,\n",
    "    mean_squared_error,\n",
    "    median_absolute_error,\n",
    "    mean_absolute_error,\n",
    "    median_absolute_error\n",
    ")\n",
    "\n",
    "# utils\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb98437",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d489d0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_root = os.path.join(\"..\",\"data\")\n",
    "\n",
    "path_primary = os.path.join(\n",
    "    path_root, \"03_primary\"\n",
    ")\n",
    "\n",
    "file_path_input_data = os.path.join(\n",
    "    path_primary, \"data_input.csv\"\n",
    ")\n",
    "\n",
    "file_path_metrics_features_test = os.path.join(\n",
    "    path_primary, \"features_test_metrics.json\"\n",
    ")\n",
    "file_path_metrics_features_selected = os.path.join(\n",
    "    path_primary, \"features_selected.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11119cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_features = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94d3a23",
   "metadata": {},
   "source": [
    "# Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fe9068",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_input = pd.read_csv(\n",
    "    file_path_input_data,\n",
    "    index_col = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a05760",
   "metadata": {},
   "source": [
    "# Shap process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62db3d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = [\n",
    "    \"price\"\n",
    "]\n",
    "cols_to_drop = [\n",
    "    \"cd_setor\",\n",
    "    \"ID\"\n",
    "] + target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c7d5e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    X = data_input.drop(cols_to_drop, axis=1)[features_selected]\n",
    "except:\n",
    "    X = data_input.drop(cols_to_drop, axis=1)\n",
    "\n",
    "y = data_input[target[0]]\n",
    "\n",
    "random_state = 42\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y, \n",
    "                                                    test_size = 0.2,\n",
    "                                                    random_state = random_state)\n",
    "\n",
    "rf_model = RandomForestRegressor()\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b34032",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.Explainer(rf_model)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "shap.summary_plot(shap_values,\n",
    "                  X_test,\n",
    "                  plot_type=\"violin\",\n",
    "                  color_bar=False, show=False)\n",
    "plt.colorbar(label='SHAP Value')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123bec09",
   "metadata": {},
   "outputs": [],
   "source": [
    "args_train = [\n",
    "    y_train.values,\n",
    "    rf_model.predict(X_train)\n",
    "]\n",
    "args_preds = [\n",
    "    y_test.values,\n",
    "    rf_model.predict(X_test)\n",
    "]\n",
    "metrics_train = {\n",
    "        \"r2\": r2_score(\n",
    "            *args_train\n",
    "        ),\n",
    "        \"mape\": mean_absolute_percentage_error(\n",
    "            *args_train\n",
    "        ),\n",
    "        \"rmse\": np.sqrt(\n",
    "            mean_squared_error(\n",
    "            *args_train\n",
    "            )\n",
    "        ),\n",
    "        \"mse\": mean_squared_error(\n",
    "            *args_train\n",
    "        ),\n",
    "        \"mae\": mean_absolute_error(\n",
    "            *args_train\n",
    "        ),\n",
    "        \"median_ae\": median_absolute_error(\n",
    "            *args_train\n",
    "        ),\n",
    "        \"correlation\": np.corrcoef(\n",
    "            *args_train\n",
    "        )[0,1],\n",
    "        \"size_train\": len(args_train[0])\n",
    "}\n",
    "\n",
    "metrics_pred = {\n",
    "        \"r2\": r2_score(\n",
    "            *args_preds\n",
    "        ),\n",
    "        \"mape\": mean_absolute_percentage_error(\n",
    "            *args_preds\n",
    "        ),\n",
    "        \"rmse\": np.sqrt(\n",
    "            mean_squared_error(\n",
    "            *args_preds\n",
    "            )\n",
    "        ),\n",
    "        \"mse\": mean_squared_error(\n",
    "            *args_preds\n",
    "        ),\n",
    "        \"mae\": mean_absolute_error(\n",
    "            *args_preds\n",
    "        ),\n",
    "        \"median_ae\": median_absolute_error(\n",
    "            *args_preds\n",
    "        ),\n",
    "        \"correlation\": np.corrcoef(\n",
    "            *args_preds\n",
    "        )[0,1],\n",
    "        \"size_test\": len(args_preds[0])\n",
    "}\n",
    "for me in [[\"train\",metrics_train], [\"test\", metrics_pred]]:\n",
    "    print(f'-------- [ {me[0]} ] ----------')\n",
    "    for metric, result in me[1].items():\n",
    "        print(f\"{metric} : {round(result, 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ac12d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize = (20,8))\n",
    "\n",
    "for content in [[0, args_train, \"Train\"], [1, args_preds, \"Test\"]]:\n",
    "    axes[content[0]].plot(content[1][0], content[1][1],\"*\")\n",
    "    axes[content[0]].set_title(content[-1])\n",
    "    axes[content[0]].set_xlabel(\"True\")\n",
    "    axes[content[0]].set_ylabel(\"Prediction\")\n",
    "    axes[content[0]].grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b43e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_preds = pd.DataFrame(args_preds, \n",
    "                          index = [\"y_true\", \"y_pred\"]).T\n",
    "data_preds = data_preds.sort_values(\"y_true\", ascending = False)\n",
    "data_preds[\"rank_true\"] = (\n",
    "    data_preds\n",
    "    .sort_values(\"y_true\", ascending = False)\n",
    "    .reset_index(drop=True)\n",
    "    .index\n",
    ")\n",
    "data_preds = data_preds.sort_values(\"y_pred\", ascending = False)\n",
    "data_preds[\"rank_pred\"] = (\n",
    "    data_preds\n",
    "    .sort_values(\"y_pred\", ascending = False)\n",
    "    .reset_index(drop=True)\n",
    "    .index\n",
    ")\n",
    "data_preds = data_preds.sample(frac=1).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539b1cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_preds.filter(regex='rank*', axis=1).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f669d863",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_importance = pd.DataFrame(\n",
    "    rf_model.feature_importances_,\n",
    "    index = rf_model.feature_names_in_,\n",
    "    columns = [\"fe\"]\n",
    ").sort_values(\"fe\", ascending = False)\n",
    "features_selected = list(\n",
    "    features_importance\n",
    "    .head(number_of_features)\n",
    "    .index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278968d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,8))\n",
    "plt.plot(data_preds['y_true'].values, label = \"true\")\n",
    "plt.plot(data_preds['y_pred'].values, label = \"pred\")\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36921a94",
   "metadata": {},
   "source": [
    "## Test cutoff of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031818a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(file_path_metrics_features_selected):\n",
    "    with open(file_path_metrics_features_selected, 'r') as json_file:\n",
    "        features_selected = json.load(json_file)\n",
    "if os.path.exists(file_path_metrics_features_test):\n",
    "    with open(file_path_metrics_features_test, 'r') as json_file:\n",
    "        metrics_all = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3271db29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "type_of = \"test\"\n",
    "chaves_internas = ['r2', 'mape', 'mae', 'median_ae','rmse','mse']\n",
    "if type_of ==\"train\":\n",
    "    chaves_internas += [\"mse\"] \n",
    "\n",
    "num_rows = 3\n",
    "num_cols = 2\n",
    "\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(18+num_rows, 9*num_cols))\n",
    "\n",
    "for i, chave_interna in enumerate(chaves_internas):\n",
    "    valores = [metrics_all[chave][type_of][chave_interna] for chave in metrics_all.keys()]\n",
    "\n",
    "    row_idx = i // num_cols\n",
    "    col_idx = i % num_cols\n",
    "    ax = axes[row_idx, col_idx]\n",
    "    \n",
    "    ax.bar(metrics_all.keys(), valores)\n",
    "    ax.set_xlabel('Chave')\n",
    "    ax.set_ylabel(chave_interna.upper())\n",
    "    ax.set_title(f'{chave_interna.upper()} por Chave')\n",
    "\n",
    "    for j, valor in enumerate(valores):\n",
    "        if chave_interna in ['r2', 'mape']:\n",
    "            ax.text(j, valor, str(round(valor, 5)), ha='center', va='bottom')\n",
    "        else:\n",
    "            ax.text(j, valor, str(round(valor, 2)), ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
